# API
Considered FastAPI, Django, and Flask
- Decided on FastAPI

## FastAPI 
Key points:
- Built on Starlette and Pydantic
- Async support out of the box
- Speed : Particularly important for handling LLM inference requests
- Automatic API documentation (OpenAPI/Swagger)
- Type checking and validation built-in
- Clear error messages
- Easy to test and debug
- Intuitive routing with decorators
- Easy to maintain

#### ML/AI Ecosystem Integration:
- Seamlessly works with PyTorch and other ML libraries
- Python is the primary language for ML/AI tasks
- Most LLM libraries (transformers, etc.) are Python-first
